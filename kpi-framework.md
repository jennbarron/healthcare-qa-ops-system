# KPI Framework (Sanitized)
## Healthcare QA Program

## Objective
Define a consistent, repeatable KPI (Key Performance Indicator) framework that measures quality performance, identifies systemic risk, and supports operational decision-making without relying on vanity metrics.

This framework balances **accuracy**, **consistency**, and **actionability**.

---

## KPI Design Principles
All KPIs followed these rules:

- **Clear definition** (no ambiguity)
- **Observable behaviors** tied to QA evaluation criteria
- **Actionable** by Operations or Training
- **Stable enough for trend analysis**
- **Suitable for automated reporting**

Metrics that could not drive a decision were excluded.

---

## Core KPI Categories

### 1) Quality Accuracy
Measures whether work met defined standards.

**Examples**
- Overall QA score
- Critical error rate
- Policy adherence rate

**Used for**
- Compliance exposure visibility
- Risk identification
- Targeted coaching prioritization

---

### 2) Consistency and Variance
Measures scoring alignment across QA reviewers and cohorts.

**Examples**
- Score variance by reviewer
- Calibration delta (pre/post alignment)
- Rework frequency tied to QA disagreement

**Used for**
- Detecting subjectivity and scoring drift
- Improving evaluator alignment
- Reducing scoring disputes and rework

---

### 3) Defect Classification
Identifies *why* quality issues occur and where intervention is needed.

**Common defect themes**
- Documentation gaps
- Policy misinterpretation
- Communication clarity issues
- Process ambiguity
- Training gaps

**Used for**
- Root-cause targeting (not individual blame)
- Training updates and process corrections
- Prioritizing fix-it work that reduces repeat errors

---

### 4) Trend and Velocity Metrics
Measures performance movement over time and validates whether changes worked.

**Examples**
- Week-over-week score movement
- Recurring defect trend lines
- Post-training improvement curves

**Used for**
- Proving impact of interventions
- Surfacing early warning signals
- Program health monitoring

---

## Reporting Structure
Reporting views were structured to match who needed the information:

- **Agent-level**: coaching and performance improvement
- **Cohort-level**: onboarding effectiveness and readiness
- **Program-level**: systemic risk, trends, and priorities

Reports were delivered on a **weekly cadence** with standardized definitions to ensure stakeholder trust.

---

## Feedback Loop Integration
This was designed as a closed-loop improvement system:

1. QA data collected and categorized
2. Trends reviewed with Operations and Training
3. Corrective actions defined (process, training, documentation)
4. Updates fed back into QA guidance and workflows
5. KPI movement tracked post-change

---

## Business Impact
This KPI framework enabled:

- Faster identification of systemic issues
- Reduced repeat errors through targeted fixes
- Improved trust in QA data across stakeholders
- Clear prioritization of operational improvements

---

## Why This Matters
This framework demonstrates the ability to:

- Translate raw QA data into operational insight
- Design metrics that support decisions
- Balance precision with real-world operations
- Build reporting leaders actually use
